********** HERE A ****************
<class 'data.scifi.SCIFIDataset'>
{'model_device': 'cuda:0', 'editor_device': 'cuda:0', 'data': {'name': 'scifi', 'n_edits': 400, 'batch_size': 32, 'train_path': '/data/sls/scratch/nmorgan/LOGIC/model_editing/malmen_changed/data_files/scifi_train.json', 'valid_path': '/data/sls/scratch/nmorgan/LOGIC/model_editing/malmen_changed/data_files/scifi_test.json'}, 'model': {'name_or_path': 'bert-large-cased', 'weight_path': '/data/sls/scratch/nmorgan/LOGIC/model_editing/malmen_changed/model_files/bert_large_cased', 'class_name': 'AutoModelForSCIFI', 'edit_modules': ['backbone.encoder.layer.18.output.dense', 'backbone.encoder.layer.19.output.dense', 'backbone.encoder.layer.20.output.dense', 'backbone.encoder.layer.21.output.dense', 'backbone.encoder.layer.22.output.dense', 'backbone.encoder.layer.23.output.dense'], 'half': False}, 'editor': {'name': 'malmen', 'rank': 1920, 'n_blocks': 2, 'lr': 1e-06, 'meta_lr': 1e-05, 'loc_coef': 1, 'max_grad_norm': 1, 'n_epochs': 1, 'batch_size': 1024, 'token': 'ans', 'cache_dir': 'cache/', 'load_checkpoint': False}}
/data/sls/scratch/nmorgan/dotfiles/miniconda3/envs/logic-edits/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
********** HERE B ****************
********** HERE C ****************
***************** RUN A *******************
*********************TRAIN A******************
1
Train:   0%|                                                                  | 0/1 [00:00<?, ?it/s]
Error executing job with overrides: []
{'edit_tuples': {'input_ids': tensor([[ 101, 1327, 1110,  ..., 1830, 1559,  102],
        [ 101, 1327, 1110,  ..., 1527,  102,    0],
        [ 101, 1327, 1110,  ..., 1161,  102,    0],
        ...,
        [ 101, 1327, 1110,  ...,    0,    0,    0],
        [ 101, 1327, 1110,  ...,    0,    0,    0],
        [ 101, 1327, 1110,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 0],
        [1, 1, 1,  ..., 1, 1, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 1,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 1],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 1,  ..., 0, 0, 0]])}, 'equiv_tuples': {'input_ids': tensor([[  101,   146,   787,  ...,     0,     0,     0],
        [  101,   168,   168,  ...,     0,     0,     0],
        [  101, 22884,  1231,  ...,     0,     0,     0],
        ...,
        [  101, 22884,  1231,  ...,     0,     0,     0],
        [  101,   146,   787,  ...,     0,     0,     0],
        [  101,   102,     0,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 0,  ..., 0, 0, 0]]), 'labels': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 1,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 1],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 1,  ..., 0, 0, 0]])}, 'unrel_tuples': {'input_ids': tensor([[ 101, 1327, 1110,  ...,    0,    0,    0],
        [ 101, 1327, 1110,  ...,    0,    0,    0],
        [ 101, 1327, 1110,  ...,    0,    0,    0],
        ...,
        [ 101, 1327, 1110,  ...,    0,    0,    0],
        [ 101, 1327, 1110,  ...,    0,    0,    0],
        [ 101, 1327, 1110,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1, 0, 0,  ..., 0, 0, 0],
        [1, 0, 0,  ..., 0, 0, 0],
        [1, 0, 0,  ..., 0, 0, 0],
        ...,
        [1, 0, 0,  ..., 0, 0, 0],
        [1, 0, 0,  ..., 0, 0, 0],
        [1, 0, 0,  ..., 0, 0, 0]])}, 'embeddings': tensor([[[-0.9533, -0.5545, -0.8401,  ...,  0.0914,  0.5349, -0.2072],
         [-0.3148, -0.3176,  0.1271,  ..., -0.1457,  0.3694,  0.3248],
         [-0.8063, -0.9523, -0.3179,  ...,  0.2746,  0.0149,  0.6167],
         ...,
         [-0.2644, -0.1592, -0.4718,  ..., -0.0808,  0.1748,  0.5790],
         [-0.4216,  0.1252,  0.2343,  ...,  0.1762,  0.1100,  0.4001],
         [ 0.0365,  0.0564, -0.9926,  ..., -0.1740,  0.0398,  0.4563]],
        [[-0.7099, -0.0687, -0.5218,  ..., -0.0654,  0.1301,  0.7600],
         [-0.4930, -0.6964, -0.6323,  ...,  0.0987,  0.3309,  0.3906],
         [-0.5448, -0.5433,  0.0638,  ...,  0.5733,  0.8763,  0.3611],
         ...,
         [-0.7046, -0.2718, -1.3876,  ..., -0.3798,  0.3351,  0.8772],
         [-0.9828,  0.2691,  0.0865,  ..., -0.1341,  0.6115, -0.5544],
         [-0.9550, -0.2889, -0.0531,  ...,  0.2825, -0.0278,  0.1637]],
        [[-0.1093,  0.7167, -0.3838,  ...,  0.1354,  0.4826,  0.1135],
         [-0.5064, -0.3906,  0.2212,  ...,  0.4018, -0.0174,  0.6506],
         [-0.5067, -0.5340, -0.5266,  ..., -0.4114, -0.1732,  0.2508],
         ...,
         [-0.0758, -0.6190,  0.4074,  ...,  0.0297, -0.3561,  0.6916],
         [-0.2266,  0.0734, -0.0276,  ..., -0.0894,  0.7747,  0.2447],
         [-0.4783, -0.1093, -0.0649,  ...,  0.2288,  0.1233,  0.4204]],
        ...,
        [[-0.2635, -0.4167, -0.2008,  ...,  0.2568,  0.0076,  0.8647],
         [-0.5274, -0.3717, -0.6470,  ...,  0.1363,  0.1381,  0.9607],
         [-0.4798, -0.1317,  0.3822,  ...,  0.0596, -0.7002,  0.4057],
         ...,
         [-0.8638, -0.4976, -0.1317,  ..., -0.2751,  0.2618,  0.3299],
         [-0.3567, -0.4472,  0.0585,  ...,  0.3466, -0.3074,  1.1296],
         [-0.6139, -0.8617, -0.7556,  ..., -0.0918, -0.3390,  0.4329]],
        [[-1.0376, -0.4396, -0.7688,  ...,  0.3267,  0.5766,  0.5935],
         [-0.5354, -0.4043, -0.4640,  ..., -0.0720,  0.3001,  0.1267],
         [-0.7442, -0.4917, -0.1220,  ..., -0.1254,  0.5411,  0.5092],
         ...,
         [-0.4900,  0.0244, -0.8392,  ...,  0.3712,  0.8611,  0.2557],
         [-0.5130, -0.8412,  0.3718,  ...,  0.8943,  0.6489,  0.4821],
         [-0.5530, -0.5068, -0.8585,  ...,  0.2523,  0.3989,  0.7589]],
        [[-0.2874, -0.1192,  0.6078,  ..., -0.1063,  1.0525, -0.0997],
         [-0.3723, -0.3937, -0.2812,  ..., -0.4210,  0.5557,  0.5356],
         [-0.7093, -0.5468, -0.7114,  ..., -0.3214, -0.3743,  0.4441],
         ...,
         [-0.0614,  0.1437, -0.3084,  ..., -0.6171,  0.2510,  0.5123],
         [ 0.0027,  0.2867, -0.3780,  ..., -0.2080,  0.0936,  0.7283],
         [-0.7452, -0.4229, -0.7210,  ...,  0.2038,  0.2311,  0.7347]]])}
*********************TRAIN B******************
Traceback (most recent call last):
  File "/data/sls/scratch/nmorgan/LOGIC/model_editing/malmen_changed/main.py", line 37, in main
    editor.run(train_loader, valid_loader)
  File "/data/sls/scratch/nmorgan/LOGIC/model_editing/malmen_changed/editor/base.py", line 178, in run
    self.train(train_loader)
  File "/data/sls/scratch/nmorgan/LOGIC/model_editing/malmen_changed/editor/base.py", line 88, in train
    self.cache(tuples["edit_tuples"])
  File "/data/sls/scratch/nmorgan/LOGIC/model_editing/malmen_changed/editor/base.py", line 158, in cache
    with TracerDict(
  File "/data/sls/scratch/nmorgan/LOGIC/model_editing/malmen_changed/util.py", line 161, in __init__
    cache_mask = tuples["labels"] != -100
TypeError: string indices must be integers
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.