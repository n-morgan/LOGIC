********** HERE A ****************
<class 'data.scifi.SCIFIDataset'>
{'model_device': 'cuda:0', 'editor_device': 'cuda:0', 'data': {'name': 'scifi', 'n_edits': 400, 'batch_size': 32, 'train_path': '/data/sls/scratch/nmorgan/LOGIC/model_editing/malmen_changed/data_files/scifi_train.json', 'valid_path': '/data/sls/scratch/nmorgan/LOGIC/model_editing/malmen_changed/data_files/scifi_test.json'}, 'model': {'name_or_path': 'bert-large-cased', 'weight_path': '/data/sls/scratch/nmorgan/LOGIC/model_editing/malmen_changed/model_files/bert_large_cased', 'class_name': 'AutoModelForSCIFI', 'edit_modules': ['backbone.encoder.layer.18.output.dense', 'backbone.encoder.layer.19.output.dense', 'backbone.encoder.layer.20.output.dense', 'backbone.encoder.layer.21.output.dense', 'backbone.encoder.layer.22.output.dense', 'backbone.encoder.layer.23.output.dense'], 'half': False}, 'editor': {'name': 'malmen', 'rank': 1920, 'n_blocks': 2, 'lr': 1e-06, 'meta_lr': 1e-05, 'loc_coef': 1, 'max_grad_norm': 1, 'n_epochs': 1, 'batch_size': 1024, 'token': 'ans', 'cache_dir': 'cache/', 'load_checkpoint': False}}
/data/sls/scratch/nmorgan/dotfiles/miniconda3/envs/logic-edits/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
********** HERE B ****************
Train:   0%|                                                                  | 0/1 [00:00<?, ?it/s]
********** HERE C ****************
***************** RUN A *******************
*********************TRAIN A******************
1
Error executing job with overrides: []
Traceback (most recent call last):
  File "/data/sls/scratch/nmorgan/LOGIC/model_editing/malmen_changed/main.py", line 37, in main
    editor.run(train_loader, valid_loader)
  File "/data/sls/scratch/nmorgan/LOGIC/model_editing/malmen_changed/editor/base.py", line 182, in run
    self.train(train_loader)
  File "/data/sls/scratch/nmorgan/LOGIC/model_editing/malmen_changed/editor/base.py", line 88, in train
    self.cache(tuples["edit_tuples"])
  File "/data/sls/scratch/nmorgan/LOGIC/model_editing/malmen_changed/editor/base.py", line 156, in cache
    print("Sample tuples[0]:", tuples[0])
KeyError: 0
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
{'edit_tuples': {'input_ids': tensor([[ 101, 1327, 1110,  ..., 1830, 1559,  102],
        [ 101, 1327, 1110,  ..., 1181,  102,    0],
        [ 101, 1327, 1110,  ..., 1580,  102,    0],
        ...,
        [ 101, 1327, 1110,  ...,    0,    0,    0],
        [ 101, 1327, 1110,  ...,    0,    0,    0],
        [ 101, 1327, 1110,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 0],
        [1, 1, 1,  ..., 1, 1, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 1, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 1],
        [0, 0, 1,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]])}, 'equiv_tuples': {'input_ids': tensor([[  101,  1731,  1110,  ...,     0,     0,     0],
        [  101, 22884,  1231,  ...,     0,     0,     0],
        [  101,   168,   168,  ...,   168,   102,     0],
        ...,
        [  101, 22884,  1231,  ...,     0,     0,     0],
        [  101,   102,     0,  ...,     0,     0,     0],
        [  101,   146,   787,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 0,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 1, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 1],
        [0, 0, 1,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]])}, 'unrel_tuples': {'input_ids': tensor([[ 101, 1327, 1110,  ...,    0,    0,    0],
        [ 101, 1327, 1110,  ...,    0,    0,    0],
        [ 101, 1327, 1110,  ...,    0,    0,    0],
        ...,
        [ 101, 1327, 1110,  ...,    0,    0,    0],
        [ 101, 1327, 1110,  ...,    0,    0,    0],
        [ 101, 1327, 1110,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1, 0, 0,  ..., 0, 0, 0],
        [1, 0, 0,  ..., 0, 0, 0],
        [1, 0, 0,  ..., 0, 0, 0],
        ...,
        [1, 0, 0,  ..., 0, 0, 0],
        [1, 0, 0,  ..., 0, 0, 0],
        [1, 0, 0,  ..., 0, 0, 0]])}, 'embeddings': tensor([[[-0.9533, -0.5545, -0.8401,  ...,  0.0914,  0.5349, -0.2072],
         [-0.3148, -0.3176,  0.1271,  ..., -0.1457,  0.3694,  0.3248],
         [-0.8063, -0.9523, -0.3179,  ...,  0.2746,  0.0149,  0.6167],
         ...,
         [-0.2644, -0.1592, -0.4718,  ..., -0.0808,  0.1748,  0.5790],
         [-0.4216,  0.1252,  0.2343,  ...,  0.1762,  0.1100,  0.4001],
         [ 0.0365,  0.0564, -0.9926,  ..., -0.1740,  0.0398,  0.4563]],
        [[-0.9789, -0.2955,  0.0505,  ...,  0.4505,  0.4775,  0.3104],
         [-0.6556, -0.8417, -0.7572,  ..., -0.0946, -0.4471,  0.0918],
         [-0.6264, -0.4917, -0.4502,  ...,  0.1885,  0.1573,  0.6561],
         ...,
         [ 0.3026, -0.1303, -0.4456,  ...,  0.7735,  0.3622,  0.7180],
         [ 0.1230, -0.1168, -0.6034,  ...,  0.0272,  0.4351,  0.0067],
         [-0.3374, -0.1897, -0.7922,  ..., -0.6387,  0.6313,  0.1439]],
        [[-0.5229, -0.4501,  0.1276,  ..., -0.0088, -0.0075,  0.6708],
         [-0.4132, -0.4963, -0.5951,  ...,  0.7176,  0.5305,  0.6235],
         [-0.4774, -0.3332, -0.4169,  ...,  0.2792,  0.4058,  0.7260],
         ...,
         [-0.9221, -0.2222, -0.2770,  ...,  0.2903,  0.3680,  1.2247],
         [-0.8172, -0.4733,  0.0933,  ...,  0.1515,  0.0923,  0.4489],
         [-0.6112,  0.1932, -0.0575,  ...,  0.0290,  0.5299,  0.5180]],
        ...,
        [[-0.4028, -0.4582, -0.5351,  ..., -0.0575,  0.7274,  0.4159],
         [-0.4551, -0.3319, -0.2761,  ...,  0.0421,  0.6834,  0.6928],
         [-0.3401, -0.3443, -0.9730,  ...,  0.1135,  0.4913,  0.7148],
         ...,
         [-0.0149,  0.0340, -0.4432,  ..., -0.1352,  0.0414,  0.7193],
         [-0.5225, -0.6378, -0.5046,  ...,  0.3036,  0.4257,  0.6338],
         [-0.5391, -0.5855, -0.7047,  ..., -0.2254, -0.4470,  0.3845]],
        [[-0.2874, -0.1192,  0.6078,  ..., -0.1063,  1.0525, -0.0997],
         [-0.3723, -0.3937, -0.2812,  ..., -0.4210,  0.5557,  0.5356],
         [-0.7093, -0.5468, -0.7114,  ..., -0.3214, -0.3743,  0.4441],
         ...,
         [-0.0614,  0.1437, -0.3084,  ..., -0.6171,  0.2510,  0.5123],
         [ 0.0027,  0.2867, -0.3780,  ..., -0.2080,  0.0936,  0.7283],
         [-0.7452, -0.4229, -0.7210,  ...,  0.2038,  0.2311,  0.7347]],
        [[-1.0376, -0.4396, -0.7688,  ...,  0.3267,  0.5766,  0.5935],
         [-0.5354, -0.4043, -0.4640,  ..., -0.0720,  0.3001,  0.1267],
         [-0.7442, -0.4917, -0.1220,  ..., -0.1254,  0.5411,  0.5092],
         ...,
         [-0.4900,  0.0244, -0.8392,  ...,  0.3712,  0.8611,  0.2557],
         [-0.5130, -0.8412,  0.3718,  ...,  0.8943,  0.6489,  0.4821],
         [-0.5530, -0.5068, -0.8585,  ...,  0.2523,  0.3989,  0.7589]]])}
*********************TRAIN B******************
Type of tuples: <class 'dict'>