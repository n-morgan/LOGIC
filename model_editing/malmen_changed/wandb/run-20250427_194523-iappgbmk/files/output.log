********** HERE A ****************
<class 'data.scifi.SCIFIDataset'>
{'model_device': 'cuda:0', 'editor_device': 'cuda:0', 'data': {'name': 'scifi', 'n_edits': 400, 'batch_size': 32, 'train_path': '/data/sls/scratch/nmorgan/LOGIC/model_editing/malmen_changed/data_files/scifi_train.json', 'valid_path': '/data/sls/scratch/nmorgan/LOGIC/model_editing/malmen_changed/data_files/scifi_test.json'}, 'model': {'name_or_path': 'bert-large-cased', 'weight_path': '/data/sls/scratch/nmorgan/LOGIC/model_editing/malmen_changed/model_files/bert_large_cased', 'class_name': 'AutoModelForSCIFI', 'edit_modules': ['backbone.encoder.layer.18.output.dense', 'backbone.encoder.layer.19.output.dense', 'backbone.encoder.layer.20.output.dense', 'backbone.encoder.layer.21.output.dense', 'backbone.encoder.layer.22.output.dense', 'backbone.encoder.layer.23.output.dense'], 'half': False}, 'editor': {'name': 'malmen', 'rank': 1920, 'n_blocks': 2, 'lr': 1e-06, 'meta_lr': 1e-05, 'loc_coef': 1, 'max_grad_norm': 1, 'n_epochs': 1, 'batch_size': 1024, 'token': 'ans', 'cache_dir': 'cache/', 'load_checkpoint': False}}
{'edit_tuples': {'input_ids': tensor([[ 101, 1327, 1110,  ..., 1830, 1559,  102],
        [ 101, 1327, 1110,  ..., 1161,  102,    0],
        [ 101, 1327, 1110,  ..., 1580,  102,    0],
        ...,
        [ 101, 1327, 1110,  ...,    0,    0,    0],
        [ 101, 1327, 1110,  ...,    0,    0,    0],
        [ 101, 1327, 1110,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 0],
        [1, 1, 1,  ..., 1, 1, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 1,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 1,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 1,  ..., 0, 0, 0]])}, 'equiv_tuples': {'input_ids': tensor([[  101,   146,   787,  ...,     0,     0,     0],
        [  101, 22884,  1231,  ...,     0,     0,     0],
        [  101,   168,   168,  ...,   168,   102,     0],
        ...,
        [  101,   102,     0,  ...,     0,     0,     0],
        [  101,  1327,   787,  ...,     0,     0,     0],
        [  101,   102,     0,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 0],
        ...,
        [1, 1, 0,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 0,  ..., 0, 0, 0]]), 'labels': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 1,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 1,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 1,  ..., 0, 0, 0]])}, 'unrel_tuples': {'input_ids': tensor([[ 101, 1327, 1110,  ...,    0,    0,    0],
        [ 101, 1327, 1110,  ...,    0,    0,    0],
        [ 101, 1327, 1110,  ...,    0,    0,    0],
        ...,
        [ 101, 1327, 1110,  ...,    0,    0,    0],
        [ 101, 1327, 1110,  ...,    0,    0,    0],
        [ 101, 1327, 1110,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1, 0, 0,  ..., 0, 0, 0],
        [1, 0, 0,  ..., 0, 0, 0],
        [1, 0, 0,  ..., 0, 0, 0],
        ...,
        [1, 0, 0,  ..., 0, 0, 0],
        [1, 0, 0,  ..., 0, 0, 0],
        [1, 0, 0,  ..., 0, 0, 0]])}, 'embeddings': tensor([[[-0.9533, -0.5545, -0.8401,  ...,  0.0914,  0.5349, -0.2072],
         [-0.3148, -0.3176,  0.1271,  ..., -0.1457,  0.3694,  0.3248],
         [-0.8063, -0.9523, -0.3179,  ...,  0.2746,  0.0149,  0.6167],
         ...,
         [-0.2644, -0.1592, -0.4718,  ..., -0.0808,  0.1748,  0.5790],
         [-0.4216,  0.1252,  0.2343,  ...,  0.1762,  0.1100,  0.4001],
         [ 0.0365,  0.0564, -0.9926,  ..., -0.1740,  0.0398,  0.4563]],
        [[-0.1093,  0.7167, -0.3838,  ...,  0.1354,  0.4826,  0.1135],
         [-0.5064, -0.3906,  0.2212,  ...,  0.4018, -0.0174,  0.6506],
         [-0.5067, -0.5340, -0.5266,  ..., -0.4114, -0.1732,  0.2508],
         ...,
         [-0.0758, -0.6190,  0.4074,  ...,  0.0297, -0.3561,  0.6916],
         [-0.2266,  0.0734, -0.0276,  ..., -0.0894,  0.7747,  0.2447],
         [-0.4783, -0.1093, -0.0649,  ...,  0.2288,  0.1233,  0.4204]],
        [[-0.5229, -0.4501,  0.1276,  ..., -0.0088, -0.0075,  0.6708],
         [-0.4132, -0.4963, -0.5951,  ...,  0.7176,  0.5305,  0.6235],
         [-0.4774, -0.3332, -0.4169,  ...,  0.2792,  0.4058,  0.7260],
         ...,
         [-0.9221, -0.2222, -0.2770,  ...,  0.2903,  0.3680,  1.2247],
         [-0.8172, -0.4733,  0.0933,  ...,  0.1515,  0.0923,  0.4489],
         [-0.6112,  0.1932, -0.0575,  ...,  0.0290,  0.5299,  0.5180]],
        ...,
        [[-0.2906,  0.3573, -1.0891,  ...,  0.0903,  0.8344, -0.0619],
         [-0.0544, -0.0111, -0.5462,  ...,  0.3775,  0.7253,  0.9528],
         [-0.4346, -0.3832, -0.9530,  ..., -0.2906, -0.2718,  0.3378],
         ...,
         [-0.4991, -0.3560, -0.0771,  ..., -0.0785,  0.1130,  0.0915],
         [-0.5284,  0.1347, -0.3430,  ..., -0.0983,  0.3600, -0.5055],
         [-1.0497, -0.6168, -0.3025,  ...,  0.0704, -0.1299,  0.9398]],
        [[-1.0376, -0.4396, -0.7688,  ...,  0.3267,  0.5766,  0.5935],
         [-0.5354, -0.4043, -0.4640,  ..., -0.0720,  0.3001,  0.1267],
         [-0.7442, -0.4917, -0.1220,  ..., -0.1254,  0.5411,  0.5092],
         ...,
         [-0.4900,  0.0244, -0.8392,  ...,  0.3712,  0.8611,  0.2557],
         [-0.5130, -0.8412,  0.3718,  ...,  0.8943,  0.6489,  0.4821],
         [-0.5530, -0.5068, -0.8585,  ...,  0.2523,  0.3989,  0.7589]],
        [[-0.2874, -0.1192,  0.6078,  ..., -0.1063,  1.0525, -0.0997],
         [-0.3723, -0.3937, -0.2812,  ..., -0.4210,  0.5557,  0.5356],
         [-0.7093, -0.5468, -0.7114,  ..., -0.3214, -0.3743,  0.4441],
         ...,
         [-0.0614,  0.1437, -0.3084,  ..., -0.6171,  0.2510,  0.5123],
         [ 0.0027,  0.2867, -0.3780,  ..., -0.2080,  0.0936,  0.7283],
         [-0.7452, -0.4229, -0.7210,  ...,  0.2038,  0.2311,  0.7347]]])}
/data/sls/scratch/nmorgan/dotfiles/miniconda3/envs/logic-edits/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(